{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(Z):\n",
    "    \"\"\"\n",
    "    Compute softmax values for each sets of scores in V.\n",
    "    each column of V is a set of score.    \n",
    "    \"\"\"\n",
    "    e_Z = np.exp(Z)\n",
    "    A = e_Z / e_Z.sum(axis = 0)\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_stable(Z):\n",
    "    \"\"\"\n",
    "    Compute softmax values for each sets of scores in Z.\n",
    "    each column of Z is a set of score.    \n",
    "    \"\"\"\n",
    "    e_Z = np.exp(Z - np.max(Z, axis = 0, keepdims = True))\n",
    "    A = e_Z / e_Z.sum(axis = 0)\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.09660193  0.83394073]\n",
      " [-0.68392005  0.29024277]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "\n",
    "# randomly generate data \n",
    "N = 2 # number of training sample \n",
    "d = 2 # data dimension \n",
    "C = 3 # number of classes \n",
    "\n",
    "X = np.random.randn(d, N)\n",
    "y = np.random.randint(0, 3, (N,))\n",
    "print(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0]\n",
      " [0 1]\n",
      " [0 0]]\n"
     ]
    }
   ],
   "source": [
    "## One-hot coding\n",
    "from scipy import sparse \n",
    "def convert_labels(y, C = C):\n",
    "    \"\"\"\n",
    "    convert 1d label to a matrix label: each column of this \n",
    "    matrix coresponding to 1 element in y. In i-th column of Y, \n",
    "    only one non-zeros element located in the y[i]-th position, \n",
    "    and = 1 ex: y = [0, 2, 1, 0], and 3 classes then return\n",
    "\n",
    "            [[1, 0, 0, 1],\n",
    "             [0, 0, 1, 0],\n",
    "             [0, 1, 0, 0]]\n",
    "    \"\"\"\n",
    "    Y = sparse.coo_matrix((np.ones_like(y), \n",
    "        (y, np.arange(len(y)))), shape = (C, len(y))).toarray()\n",
    "    return Y \n",
    "\n",
    "Y = convert_labels(y, C)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yi (3, 1) ai (3, 1) xi (2, 1)\n",
      "(2, 3)\n",
      "(2, 3)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def softmax_regression(X, y, W_init, eta, tol = 1e-4, max_count = 10000):\n",
    "    W = [W_init]    \n",
    "    C = W_init.shape[1]\n",
    "    Y = convert_labels(y, C)\n",
    "    it = 0\n",
    "    N = X.shape[1]\n",
    "    d = X.shape[0]\n",
    "    \n",
    "    count = 0\n",
    "    check_w_after = 20\n",
    "    while count < max_count:\n",
    "        # mix data \n",
    "        mix_id = np.random.permutation(N)\n",
    "        for i in mix_id:\n",
    "            xi = X[:, i].reshape(d, 1)\n",
    "            yi = Y[:, i].reshape(C, 1)\n",
    "            ai = softmax(np.dot(W[-1].T, xi))\n",
    "            W_new = W[-1] + eta*xi.dot((yi - ai).T)\n",
    "            # print(\"yi\",yi.shape,\"ai\",ai.shape,\"xi\",xi.shape)\n",
    "            # print((eta*xi.dot((yi - ai).T)).shape)\n",
    "            # print(W_new.shape)\n",
    "            # input()\n",
    "            count += 1\n",
    "            # stopping criteria\n",
    "            if count%check_w_after == 0:                \n",
    "                if np.linalg.norm(W_new - W[-check_w_after]) < tol:\n",
    "                    return W\n",
    "            W.append(W_new)\n",
    "    return W\n",
    "eta = .05 \n",
    "d = X.shape[0]\n",
    "W_init = np.random.randn(d, C)\n",
    "\n",
    "W = softmax_regression(X, y, W_init, eta)\n",
    "# W[-1] is the solution, W is all history of weights\n",
    "print(W[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred(W, X):\n",
    "    \"\"\"\n",
    "    predict output of each columns of X\n",
    "    Class of each x_i is determined by location of max probability\n",
    "    Note that class are indexed by [0, 1, 2, ...., C-1]\n",
    "    \"\"\"\n",
    "    A = softmax_stable(W.T.dot(X))\n",
    "    return np.argmax(A, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 1500)\n"
     ]
    }
   ],
   "source": [
    "means = [[2, 2], [8, 3], [3, 6]]\n",
    "cov = [[1, 0], [0, 1]]\n",
    "N = 500\n",
    "X0 = np.random.multivariate_normal(means[0], cov, N)\n",
    "X1 = np.random.multivariate_normal(means[1], cov, N)\n",
    "X2 = np.random.multivariate_normal(means[2], cov, N)\n",
    "\n",
    "# each column is a datapoint\n",
    "X = np.concatenate((X0, X1, X2), axis = 0).T \n",
    "# extended data\n",
    "X = np.concatenate((np.ones((1, 3*N)), X), axis = 0)\n",
    "print(X.shape)\n",
    "C = 3\n",
    "\n",
    "original_label = np.asarray([0]*N + [1]*N + [2]*N).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(785, 60000)\n",
      "(785, 10000)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Tải dữ liệu MNIST và chia thành tập huấn luyện và tập kiểm tra\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Chuẩn hóa dữ liệu và chuyển đổi nhãn thành one-hot encoding\n",
    "train_images = train_images.astype('float32') / 255\n",
    "test_images = test_images.astype('float32') / 255\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)\n",
    "#flatten train and test img\n",
    "train_images = train_images.reshape(60000,784)\n",
    "train_images = np.concatenate((np.ones((60000,1)),train_images), axis = 1).T\n",
    "print(train_images.shape)\n",
    "test_images = test_images.reshape(10000,784)\n",
    "test_images = np.concatenate((np.ones((10000,1)),test_images), axis = 1).T\n",
    "print(test_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_init = np.random.randn(X.shape[0], C)\n",
    "W = softmax_regression(X, original_label, W_init, eta)\n",
    "print(W[-1])\n",
    "print(pred(W[-1],X))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
